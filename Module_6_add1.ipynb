{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2o6dIJYv0M_f"
   },
   "source": [
    "# **Module 6**\n",
    "In this module, we will use two open-source scientific computing packages for Python - Numpy and Scipy. \n",
    "\n",
    "* Numpy is used to create n-dimensional arrays and matrices operations and solve linear equations. Scipy is built on top of Numpy. \n",
    "\n",
    "* It contains a number of sub-packages important for engineering, scientific, and statistical computing. \n",
    "\n",
    "* We will use Scipy to generate random variables based on a variety of discrete and continuous distributions. \n",
    "\n",
    "* We will also use Scipy to conduct statistical analysis of data and detect anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPB51znJ0PCj"
   },
   "source": [
    "## **1. Numpy Array Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "n5hMudXM0wF9"
   },
   "outputs": [],
   "source": [
    "#import Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy \n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tulDIiSl5DKZ"
   },
   "source": [
    "**1. Let generates a 3x3 NumPy array and then converts it into a one-dimensional array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hhYyZQjO0rxP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate 3x3 array \n",
    "array_3D = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "#Convert to 1D array\n",
    "array_1d = array_3D.flatten()\n",
    "array_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15, 17, 10, 11],\n",
       "       [ 8, 19,  6,  2],\n",
       "       [ 7,  1,  3,  0],\n",
       "       [ 2, 11,  6, 17]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate 4x4 random integer array \n",
    "array_4x4 = np.random.randint(0, 20, size=(4, 4))\n",
    "array_4x4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUErpBkd5j6v"
   },
   "source": [
    "**2. Let us use the NumPy to generate a 4x4 array of random integers between 0 and 10, and then calculate the mean, median, and standard deviation of the array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "41GBavVZ0z-Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 8.4375\n",
      "Median: 7.5\n",
      "Std_dev: 5.968340954570206\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Calculate mean, median, and standard deviation\n",
    "mean = np.mean(array_4x4)\n",
    "median = np.median(array_4x4)\n",
    "std_dev = np.std(array_4x4)\n",
    "\n",
    "print(\"Mean:\",mean)\n",
    "print(\"Median:\",median)\n",
    "print(\"Std_dev:\",std_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsMUa12X58G3"
   },
   "source": [
    "**3. Slicing**\n",
    "\n",
    "* Let creates a 5x5 identity matrix and then slices the matrix to obtain a 3x3 sub-matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "B8im56vu0MZ_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 5x5 identity matrix \n",
    "identity_matrix = np.identity(5)\n",
    "\n",
    "#Slice to obtain 3x3 sub-matrix\n",
    "sub_matrix = identity_matrix[0:3, 0:3]\n",
    "\n",
    "print(identity_matrix)\n",
    "sub_matrix[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3M68Zqf051u"
   },
   "source": [
    "##**2. Statistical Properties**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44, 20,  6, 37, 13],\n",
       "       [49, 55, 33, 64,  1],\n",
       "       [52, 73, 42, 36, 26],\n",
       "       [35, 99, 12, 35, 57],\n",
       "       [23, 55, 39, 66,  3]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_5x5 = np.random.randint(0, 100, size=(5, 5))\n",
    "array_5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZkQvggnX1Be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum: 99\n",
      "minimum: 19\n",
      "range_: 80\n"
     ]
    }
   ],
   "source": [
    "# 1. Generate 5x5 array and calculate maximum, minimum, and range\n",
    "array_5x5 = np.random.randint(0, 100, size=(5, 5))\n",
    "maximum = np.max(array_5x5)\n",
    "minimum = np.min(array_5x5)\n",
    "range_ = np.ptp(array_5x5)\n",
    "print(\"maximum:\",maximum)\n",
    "print(\"minimum:\",minimum)\n",
    "print(\"range_:\",range_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "XJVZTcBD1MVe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5242640985197536"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Calculate correlation coefficient between two arrays\n",
    "array_1 = np.random.randint(0, 10, size=10)\n",
    "array_2 = np.random.randint(0, 10, size=10)\n",
    "corr_coeff = np.corrcoef(array_1, array_2)[0][1]\n",
    "corr_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "rOM2Xs_Z1IYq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44926246,  0.88577211,  0.10524126,  0.53878686,  0.52298218],\n",
       "       [ 0.49530549,  0.04542353,  0.68966014,  0.34129135, -0.84805755],\n",
       "       [-0.52521572,  0.44049401, -0.35532238,  1.2124192 , -1.60569138],\n",
       "       [ 0.11988962,  0.2158606 , -0.12673018,  0.80101273,  1.16698381],\n",
       "       [-1.06269458,  0.19836834, -1.74469015,  0.82008012, -0.20629129]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Generate 5x5 normally distributed array and calculate skewness and kurtosis\n",
    "norm_array = np.random.normal(loc=0, scale=1, size=(5, 5))\n",
    "skewness = scipy.stats.skew(norm_array)\n",
    "kurtosis = scipy.stats.kurtosis(norm_array)\n",
    "norm_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mxS_SE91VVG"
   },
   "source": [
    "## **3. Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiEifTKG1c4H"
   },
   "outputs": [],
   "source": [
    "# 1. Generate Poisson distribution and calculate PMF, PDF, and CDF\n",
    "poisson_dist = np.random.poisson(lam=3, size=1000)\n",
    "pmf = np.histogram(poisson_dist, bins=np.arange(11))[0]/len(poisson_dist)\n",
    "pdf = scipy.stats.poisson.pmf(np.arange(11), mu=3)\n",
    "cdf = scipy.stats.poisson.cdf(np.arange(11), mu=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXCNEIZY1dKs"
   },
   "outputs": [],
   "source": [
    "# 2. Generate normal distribution and calculate PDF and CDF\n",
    "norm_dist = np.random.normal(loc=5, scale=2, size=1000)\n",
    "pdf = scipy.stats.norm.pdf(np.arange(0, 11, 0.1), loc=5, scale=2)\n",
    "cdf = scipy.stats.norm.cdf(np.arange(0, 11, 0.1), loc=5, scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cLb-GU-1ou_"
   },
   "source": [
    "## **4. A/B Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5bl0vGE4HXC"
   },
   "source": [
    "**1. Let us write a Python code that generates two arrays of random integers between 0 and 10 with a sample size of 10.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQafC6751xvo"
   },
   "outputs": [],
   "source": [
    "# Generate two arrays and conduct t-test\n",
    "array_1 = np.random.randint(0, 10, size=10)\n",
    "array_2 = np.random.randint(0, 10, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tnEx1aa4Wfj"
   },
   "source": [
    "**2. Let use Scipy to conduct a t-test to compare the means of the two arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpsCfbov4f_0"
   },
   "outputs": [],
   "source": [
    "t_test = scipy.stats.ttest_ind(array_1, array_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOKt208Z4iOM"
   },
   "source": [
    "**3. Let us use Scipy to conduct a chi-square test on two arrays of random integers between 0 and 5 with a sample size of 100.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9bUyoV11x5H"
   },
   "outputs": [],
   "source": [
    "# Conduct chi-square test on two arrays\n",
    "array_1 = np.random.randint(0, 5, size=100)\n",
    "array_2 = np.random.randint(0, 5, size=100)\n",
    "chi_square = scipy.stats.chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two arrays for observed data\n",
    "observed_data = np.array([[10, 20], [30, 40]])\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2, p, dof, expected = scipy.stats.chi2_contingency(observed_data)\n",
    "\n",
    "# Print the results\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "print(\"Expected frequencies table:\")\n",
    "print(expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvmOuQXP164r"
   },
   "source": [
    "## **5. Anomaly Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGe9N_BW3LDu"
   },
   "outputs": [],
   "source": [
    "# Import Librarie\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIYcXyE13LkY"
   },
   "source": [
    "1. Let us write a Python code that generates a 5x5 array of random integers between 0 and 10 with one value that is significantly larger than the others. Now let use NumPy to detect the anomaly and replace the value with the mean of the other values in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Yx-FgPs3WyS"
   },
   "outputs": [],
   "source": [
    "# Generate random 5x5 array with one significantly larger value\n",
    "arr = np.random.randint(0, 10, size=(5, 5))\n",
    "arr[3, 3] = 100 #sets one value to 100 to represent the anomaly\n",
    "\n",
    "# Detect anomaly using NumPy and replace with mean of other values\n",
    "mean = np.mean(arr)\n",
    "std = np.std(arr)\n",
    "threshold = mean + 3*std\n",
    "anomaly_mask = arr > threshold\n",
    "if np.any(anomaly_mask):\n",
    "    arr[anomaly_mask] = mean\n",
    "\n",
    "# Print original array and array with anomaly replaced\n",
    "print(\"Original array:\")\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xXyYvJe3tJb"
   },
   "source": [
    "2. Generate a random dataset with anomalies, detects the anomalies using both the z-score and percentile methods, and removes the anomalies from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8ozfnmp2COs"
   },
   "outputs": [],
   "source": [
    "# Generate random data with anomalies\n",
    "data = np.random.normal(0, 1, 100)\n",
    "anomalies = np.random.normal(10, 1, 3)\n",
    "data = np.concatenate((data, anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yboGFFNJ2uUy"
   },
   "outputs": [],
   "source": [
    "# Convert data to pandas dataframe\n",
    "df = pd.DataFrame(data, columns=['Values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qYCK7kF2wvg"
   },
   "outputs": [],
   "source": [
    "# Detect anomalies using z-score method\n",
    "df['Z-score'] = (df['Values'] - df['Values'].mean()) / df['Values'].std()\n",
    "anomalies_zscore = df.loc[df['Z-score'].abs() > 3, 'Values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsalZERs2y-v"
   },
   "outputs": [],
   "source": [
    "# Remove anomalies using z-score method\n",
    "df = df.loc[df['Z-score'].abs() <= 3, :].drop(columns=['Z-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yskuqt9g21t2"
   },
   "outputs": [],
   "source": [
    "# Detect anomalies using percentile method\n",
    "q1, q3 = np.percentile(df['Values'], [25, 75])\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "anomalies_percentile = df.loc[(df['Values'] < lower_bound) | (df['Values'] > upper_bound), 'Values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9INQEBei242r"
   },
   "outputs": [],
   "source": [
    "# Remove anomalies using percentile method\n",
    "df = df.loc[(df['Values'] >= lower_bound) & (df['Values'] <= upper_bound), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nActLuZA2CaL"
   },
   "outputs": [],
   "source": [
    "print('Original data:')\n",
    "print(data)\n",
    "print('Anomalies detected using Z-score method:')\n",
    "print(anomalies_zscore.values)\n",
    "print('Anomalies detected using percentile method:')\n",
    "print(anomalies_percentile.values)\n",
    "print('Data after removing anomalies:')\n",
    "print(df['Values'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yPB51znJ0PCj",
    "i3M68Zqf051u",
    "3mxS_SE91VVG",
    "_cLb-GU-1ou_",
    "IvmOuQXP164r"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
